{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1KI5HO6c0MQy"
   },
   "source": [
    "# Redes neuronales convolucionales \n",
    "\n",
    "En este cuaderno vamos a construir redes neurnales convolucionales (_Convolutional Neural Networks_, CNN).\n",
    "\n",
    "+ Este tipo de redes se caracteriza porque las neuronas de una capa NO se conectan con todas las neuronas de la capa anterior, sino que se conectan a un pequeño grupo de ellas, que además tienen una relación de vecindad.\n",
    "+ La combinación lineal de las entradas que se realiza dentro de cada neurona se puede interpretar como si los pesos fueran un filtro de convolución (o correlación) y por tanto su salida será alta cuando la vecindad que están evaluando se parece a dicho filtro. \n",
    "+ Cuando se aplica a imágenes, el resultado es otra imagen donde las vecindades con mayor intensidad son aquellos que se parecen al filtro. \n",
    "+ Si en vez de un único filtro aprendemos varios, entonces estamos extrayendo aquellas características visuales de bajo nivel que se parezcan a los filtros que se aprendan.\n",
    "+ Las CNN intercalan neuronas convolucionales con etapas de agrupamiento (_pooling_) para aproximar aquellos píxeles resultantes de la convolución que han sido resaltados por los filtros.\n",
    "\n",
    "---\n",
    "\n",
    "    [ES] Código de Alfredo Cuesta Infante para 'Reconocimiento de Patrones'\n",
    "       @ Master Universitario en Visión Artificial, 2020, URJC (España)\n",
    "    [EN] Code by Alfredo Cuesta-Infante for 'Pattern Recognition'\n",
    "       @ Master of Computer Vision, 2020, URJC (Spain)\n",
    "\n",
    "    alfredo.cuesta@urjc.es    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Kd8kmCJ8FzY"
   },
   "outputs": [],
   "source": [
    "#-[0]. General purpose packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a36yDHQK0Tny"
   },
   "source": [
    "**Cargar el MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8585,
     "status": "ok",
     "timestamp": 1573748153656,
     "user": {
      "displayName": "alfredo cuesta infante Universidad Rey Juan Carlos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD0b4XSkrh_rJCoTmgJ-8PhQuMJ0ghZkDfkaDYb=s64",
      "userId": "17488335604138000921"
     },
     "user_tz": -60
    },
    "id": "1-qDDIYSvF0W",
    "outputId": "1572443e-5264-4a48-9c42-d0b9957728b1"
   },
   "outputs": [],
   "source": [
    "#-[1]. Load images. Keras has a few benchmark datasets readily available.\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#--- Get info of train and test data sets\n",
    "N_train,dim0,dim1 = x_train.shape\n",
    "N_test,dim0,dim1  = x_test.shape\n",
    "num_classes = 10\n",
    "num_pixels = dim0*dim1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kjWNP6d00bdG"
   },
   "source": [
    "### Construcción de la red\n",
    "+ Una red convolucional básica (tipo LeNet o AlexNet) tiene:\n",
    "    + Una capa de entrada\n",
    "    + Una o varias etapas convolución y agrupamiento\n",
    "    + Un cabezal clasificador\n",
    "\n",
    "Keras nos proporciona objetos para replicar esta estructura de capas\n",
    "+ **La capa de entrada** es similar a la capa de entrada de las redes densas.\n",
    "+ **Cada etapa de convolución y agrupamiento** consiste en una capa con neuronas convolucionales, con una cierta activación, seguida de una capa de agrupamiento, típicamente _MaxPooling_.\n",
    "+ **El cabezal clasificador** es una red neuronal para clasificar que utiliza como entrada el mapa de características producido por la última etapa de convolución+agrupamiento serializado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1647,
     "status": "ok",
     "timestamp": 1573748271480,
     "user": {
      "displayName": "alfredo cuesta infante Universidad Rey Juan Carlos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD0b4XSkrh_rJCoTmgJ-8PhQuMJ0ghZkDfkaDYb=s64",
      "userId": "17488335604138000921"
     },
     "user_tz": -60
    },
    "id": "RtdiOOonwUcU",
    "outputId": "f139655c-be7d-4e5f-9fa4-7988868dffba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 26,266\n",
      "Trainable params: 26,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#- Input layer\n",
    "x = Input( shape=(dim0, dim1, 1) ) \n",
    "\n",
    "#- Convolution+Pooling layers\n",
    "h = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "h = MaxPooling2D((2, 2))(h)\n",
    "h = Conv2D(16, (3, 3), activation='relu', padding='same')(h)\n",
    "h = MaxPooling2D((2, 2))(h)\n",
    "h = Conv2D(32, (3, 3), activation='relu', padding='same')(h)\n",
    "z = MaxPooling2D((2, 2))(h)\n",
    "\n",
    "#- Classification header\n",
    "z = Flatten()(z)\n",
    "z = Dense(64, activation='relu')(z)\n",
    "y = Dense(num_classes, activation='softmax')(z)\n",
    "\n",
    "#- Put all in a model and compile\n",
    "cnn = Model(x,y)\n",
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3CfLnCDn7trc"
   },
   "source": [
    "## Aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Preparamos el conjunto de datos para que pueda ser procesado por el modelo**  <br>\n",
    "       _En este caso NO hace falta serializar las imágenes ya que la entrada de las CNN es típicamente imágenes._<br>\n",
    "       Es importante reflejar la profundidad de color. Normalmente será 1 para imágenes en escala de grises y 3 para RGB. <br>\n",
    "       Pero podría ser otro, por ejemplo 4 para RGB-D\n",
    "       \n",
    "**2. Preparamos también el vector de etiquetas para que tenga una representación 1-hot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FYqb-Py14xRK"
   },
   "outputs": [],
   "source": [
    "x_tensor = x_train.reshape((N_train,dim0,dim1,1))\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_1hot = to_categorical(y_train, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Ejecutar el método FIT**<br>estandar\n",
    "_Tensorflow sigue el estandar de Scikit-Learn. Pero a diferencia de otros métodos que hemos visto de ML, en DL hay que especificar algunas otra opciones como el número de épocas o el tamaño del lote.\n",
    "+ El **número de épocas** indica cuantas veces se utiliza el conjunto de entrenamiento para realizar el aprendizaje\n",
    "+ El **tamaño del lote** es el número de muestras que se utilizan para calcular el descenso del gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 780
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 502206,
     "status": "ok",
     "timestamp": 1573749611159,
     "user": {
      "displayName": "alfredo cuesta infante Universidad Rey Juan Carlos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD0b4XSkrh_rJCoTmgJ-8PhQuMJ0ghZkDfkaDYb=s64",
      "userId": "17488335604138000921"
     },
     "user_tz": -60
    },
    "id": "Ta4SlQ_x244O",
    "outputId": "10b115c4-36a5-44da-b695-ec45e7d80764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0195186b50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "\n",
    "N_epochs = 1\n",
    "batch_size = 32\n",
    "cnn.fit(x_tensor, y_1hot, epochs=N_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JCOOvn-U8yIy"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H23IeqsK_A76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 <-- y\n",
      "8 <-- yhat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f014dff6a90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = x_test.reshape((N_test,dim0,dim1,1))\n",
    "yhat = cnn.predict(x)\n",
    "\n",
    "k = 1234\n",
    "print(y_test[k] ,'<-- y')\n",
    "print(np.argmax(yhat[k,:]) ,'<-- yhat')\n",
    "plt.imshow(x_test[k,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. Encapsular la construcción de la red en dos funciones:\n",
    "    + Una que reciba las imágenes de entrada y devuelva el mapa de características mediante una serie de etapas convolucionales+agrupamiento\n",
    "    + Y un cabezal clasificador construido con una *Fully Connected* de 10 salidas (una por clase).\n",
    "\n",
    "    Interesa que las funciones reciban como argunmento una lista de manera que que podamos configurar diferentes redes al invocarlas\n",
    "        \n",
    "        \n",
    "2. Crear un cabezal regresor utilizando únicamente neuronas convolucionales"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "a36yDHQK0Tny",
    "kjWNP6d00bdG",
    "4w2Y9htI2Ix2"
   ],
   "name": "02_keras_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
