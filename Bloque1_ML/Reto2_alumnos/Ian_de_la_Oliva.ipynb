{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 2: Problema multiclase\n",
    "\n",
    "Este reto consiste en aprender a clasificar 4 tipos diferentes de vehículos utilizando cualquiera de los clasificadores o técnicas estudiadas hasta el momento. Esto incluye:\n",
    "+ clasificación lineal\n",
    "+ transformaciones no lineales seguido de un clasificador lineal\n",
    "+ Support Vector Machines (SVM)\n",
    "+ Decision Tree (DT)\n",
    "\n",
    "Además se pueden aplicar técnicas de preprocesado como:\n",
    "+ escalado de las características\n",
    "+ *grid search* para búsqueda de hiperparámetros\n",
    "+ validación cruzada\n",
    "\n",
    "El conjunto de datos, *vehiculos_reto2.csv*, consiste en 592 muestras de vehículos; cada uno de ellos representado por 18 características.\n",
    "\n",
    "Para evaluar las propuestas se utilizará un conjunto de datos que se mantendrá oculto hasta después de la entrega\n",
    "\n",
    "### Requisitos\n",
    "+ La entrega se realiza **sólo** a través de la tarea habilitada para ello en la pestaña de *Evaluación* del Aula Virtual.\n",
    "+ Se debe entregar un cuaderno Jupyter con el nombre de los participantes.<br>\n",
    "  *Por ejemplo*:   **Cuesta_LeCunn.ipynb**\n",
    "+ El cuaderno entregado debe seguir la estructura y reglas de este cuaderno\n",
    "\n",
    "### Competición\n",
    "+ Todos los cuadernos entregados se subirán al repo de GitHub y se ejecutarán en Binder, donde ya estará en conjunto de test que permanecía oculto.\n",
    "+ El número de aciertos respecto del número de ejemplos será la puntuación del reto.\n",
    "+ **Importante** Es muy fácil asegurarte de que tu código funcionará bien. Para ello:\n",
    "    1. Agrupa todo tu código en una única celda\n",
    "    2. En el cuaderno del reto que hay en Binder: elimina las celdas que hay entre la verde y la roja, y copia tu celda entre ellas.\n",
    "    3. Ejecuta ese cuaderno de Binder. \n",
    "    \n",
    "### Plazo: lunes 26 de oct. de 2020 a las 6 am.\n",
    "Es decir, incluye toda la noche del domingo 25 de oct.\n",
    "\n",
    "\n",
    "---\n",
    "    [ES] Código de Alfredo Cuesta Infante para 'Reconocimiento de Patrones'\n",
    "       @ Master Universitario en Visión Artificial, 2020, URJC (España)\n",
    "    [EN] Code by Alfredo Cuesta-Infante for 'Pattern Recognition'\n",
    "       @ Master of Computer Vision, 2020, URJC (Spain)\n",
    "\n",
    "    alfredo.cuesta@urjc.es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto distribuido para el reto\n",
    "\n",
    "Challange_filename = '../../Datasets/vehiculos_reto2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto NO distribuido para evaluar los clasificadores entregados\n",
    "\n",
    "Test_filename = '../../Datasets/vehiculos_test.csv' #<-- este nombre cambiará después del plazo de entrega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-[1]. Load data from CSV and put all in a single dataframe 'FullSet'\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../../MyUtils/')\n",
    "import MyUtils as my\n",
    "seed = 1234 #<- random generator seed (comment to get randomness)\n",
    "\n",
    "#-[2]. Load data from CSV and put all in a single dataframe 'FullSet'\n",
    "\n",
    "FullSet = pd.read_csv(Challange_filename, header=0)\n",
    "FullX = FullSet.drop('Class', axis=1)\n",
    "FullY = FullSet[['Class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%;\"> \n",
    " <tr style='background:lime'>\n",
    "  <td style=\"text-align:left\">\n",
    "      <h2>Tu código debe empezar a partir de aquí y puede tener tantas celdas como quieras</h2>\n",
    "      <p> Si quieres, puedes borrar (o convertir en RawNBConvert) las celdas de ejemplo\n",
    "      <h3>Importante:</h3>\n",
    "      <p>Tu código debe producir las siguientes variables: </p>\n",
    "      <p> $\\quad \\bullet$ <b>clf:</b> el clasificador final con el que se realizará el test<br>\n",
    "       $\\quad \\bullet$ <b>X_test:</b> el conjunto de test listo para ser usado por el método <b>predict</b><br>\n",
    "       $\\quad \\bullet$ <b>Y_test:</b> es el vector de etiquetas del conjunto de X_test listo para ser usado por el método <b>confusion_matrix</b>\n",
    "      </p>\n",
    "  </td>\n",
    " </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres = [\"Ian de la Oliva\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajo realizado:\n",
    "+ Prueba de modelos previa--> Solo voy a trabajar con SVM.\n",
    "+ Pasos en cada modelo.\n",
    "    - Train/test al 0.5, 0.4, 0.3 (para test).\n",
    "    - Escalamos el train. Escalamos test con los parámetros de train.\n",
    "    - Realizamos un random grid search con los parámetros de la celda de abajo. Normalmente 500 iteraciones y cross validation entre 3 y 5.\n",
    "+ He realizado 50 veces el paso anterior (pocos minutos) para cada separación. Selecciono el ganador y me quedo con ese estimador. \n",
    "+ Después de ejecutar este proceso 3 veces tengo 3 clasificadores:\n",
    "    - SVC(C=1300, coef0=0.2, degree=53, gamma=0.256, tol=0.002)\n",
    "    - SVC(C=200, coef0=8.0, degree=66, gamma=0.171, tol=0.002)\n",
    "    - SVC(C=100, coef0=2.8, degree=20, gamma=0.785, tol=0.003)\n",
    "+ Compruebo cada uno de estos estimadores realizando una media de los resultados en test de dividir (y entrenar) el conjunto inicia. Esto lo hago para tener una consistencia ya que los resultados varian mucho segun la division de train test. Seleccionamos el ganador.\n",
    "+ Por último entreno el ganador sobre todo el conjunto (por ser muy pequeño) para que la explotación sea la mejor."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "parameters = {\n",
    "    'C':            [0.01,0.05,0.1,0.5,1,2,5,10,20,50,100,200,500,800, 900,1000,1100,1200,1300],\n",
    "    'kernel':       ['linear', 'rbf'],      \n",
    "    'degree':       np.arange( 0, 100+0, 1 ).tolist(),\n",
    "    'gamma':        np.arange( 0.0, 1.0, 0.001 ).tolist(),\n",
    "    'coef0':        np.arange( 0.0, 10.0+0.0, 0.1 ).tolist(),\n",
    "    'tol':          np.arange( 0.001, 0.005+0.001, 0.001 ).tolist(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a_ant= 0\n",
    "test_size = 0.3\n",
    "\n",
    "for j in range(50):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(FullX,FullY, test_size=test_size)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    Y_train = Y_train.values.ravel() \n",
    "    Y_test = Y_test.values.ravel() \n",
    "    \n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf_ = RandomizedSearchCV(n_iter = 500, \n",
    "                                           estimator           = SVC(),\n",
    "                                           param_distributions = parameters,\n",
    "                                           n_jobs              = 4,\n",
    "                                           iid                 = True,\n",
    "                                           refit               = True,\n",
    "                                           cv                  = 3,\n",
    "                                           verbose             = 1,\n",
    "                                           pre_dispatch        = '2*n_jobs'\n",
    "                                           )\n",
    "\n",
    "    clf_.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf_.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    clf = clf_.best_estimator_.fit(X_train, Y_train)\n",
    "    Y_hat = clf.predict(X_test)\n",
    "    conf_mat = confusion_matrix(Y_test , Y_hat)\n",
    "    N_success  = np.trace(conf_mat)\n",
    "    N_fails = Y_test.shape[0]-N_success\n",
    "    a = 100*N_success/(N_success+N_fails)\n",
    "    if a > a_ant :\n",
    "        a_ant =a \n",
    "        CLF = clf\n",
    "        print(CLF, a_ant)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CLF,a_ant"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "suma = 0\n",
    "for j in range(50):\n",
    "    test_size = 0.5\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(FullX,FullY, test_size=test_size)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    Y_train = Y_train.values.ravel() \n",
    "    Y_test = Y_test.values.ravel() \n",
    "    clf = SVC(C=1300, coef0=0.2, degree=53, gamma=0.256, tol=0.002)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_hat = clf.predict(X_test)\n",
    "    conf_mat = confusion_matrix(Y_test , Y_hat)\n",
    "    N_success  = np.trace(conf_mat)\n",
    "    N_fails = Y_test.shape[0]-N_success\n",
    "    suma+= 100*N_success/(N_success+N_fails)\n",
    "print(suma/50)\n",
    "suma = 0\n",
    "for j in range(50):\n",
    "    test_size = 0.4\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(FullX,FullY, test_size=test_size)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    Y_train = Y_train.values.ravel() \n",
    "    Y_test = Y_test.values.ravel() \n",
    "    clf = SVC(C=200, coef0=8.0, degree=66, gamma=0.171, tol=0.002)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_hat = clf.predict(X_test)\n",
    "    conf_mat = confusion_matrix(Y_test , Y_hat)\n",
    "    N_success  = np.trace(conf_mat)\n",
    "    N_fails = Y_test.shape[0]-N_success\n",
    "    suma+= 100*N_success/(N_success+N_fails)\n",
    "print(suma/50)\n",
    "suma = 0\n",
    "for j in range(50):\n",
    "    test_size = 0.3\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(FullX,FullY, test_size=test_size)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    Y_train = Y_train.values.ravel() \n",
    "    Y_test = Y_test.values.ravel() \n",
    "    clf = SVC(C=100, coef0=2.8, degree=20, gamma=0.785, tol=0.003)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_hat = clf.predict(X_test)\n",
    "    conf_mat = confusion_matrix(Y_test , Y_hat)\n",
    "    N_success  = np.trace(conf_mat)\n",
    "    N_fails = Y_test.shape[0]-N_success\n",
    "    suma+= 100*N_success/(N_success+N_fails)\n",
    "print(suma/50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ian de la Oliva'] \n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[153   0   0   0]\n",
      " [  0 144   4   0]\n",
      " [  0   8 144   0]\n",
      " [  0   0   0 139]] \n",
      "\n",
      "Outcome:\n",
      "\n",
      "  :) HIT  = 580, (97.97%)\n",
      "  :( FAIL = 12, (2.03%)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(FullX)\n",
    "#X_test = scaler.transform(X_test)\n",
    "Y_train = FullY.values.ravel() \n",
    "#Y_test = Y_test.values.ravel() \n",
    "clf =  SVC(C=100, coef0=2.8, degree=20, gamma=0.785, tol=0.003)\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_hat = clf.predict(X_train)\n",
    "conf_mat = confusion_matrix(Y_train , Y_hat)\n",
    "N_success  = np.trace(conf_mat)\n",
    "N_fails = Y_train.shape[0]-N_success\n",
    "print (nombres,\"\\n\")\n",
    "print(\"Confusion matrix:\\n\")\n",
    "print(conf_mat,\"\\n\")\n",
    "print(\"Outcome:\\n\")\n",
    "strlog = \"  :) HIT  = %d, (%0.2f%%)\"%(N_success, 100*N_success/(N_success+N_fails))\n",
    "print(strlog)\n",
    "strlog = \"  :( FAIL = %d, (%0.2f%%)\"%(N_fails, 100*N_fails/(N_success+N_fails))\n",
    "print(strlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RESULTADO: X_test es el dataframe para utilizar en >>> Y_pred = clf.predict() \\n   RESULTADO: Y_test es el array con las etiquetas para utilizar en >>> confusion_matrix(Y_test,Y_pred)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- ejemplo de test --\n",
    "\n",
    "FullSet = pd.read_csv(Test_filename, header=0)\n",
    "TestX_ = FullSet.drop('Class', axis=1)\n",
    "TestY_ = FullSet[['Class']]\n",
    "X_test = scaler.transform(TestX_)\n",
    "Y_test = TestY_.values.ravel() \n",
    "#-la evaluación se realiza en las celdas de abajo\n",
    "\n",
    "'''RESULTADO: X_test es el dataframe para utilizar en >>> Y_pred = clf.predict() \n",
    "   RESULTADO: Y_test es el array con las etiquetas para utilizar en >>> confusion_matrix(Y_test,Y_pred)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%;\"> \n",
    " <tr style='background:pink'>\n",
    "  <td style=\"text-align:left\">\n",
    "      <h2>A partir de aquí ya no se pueden modificar las celdas</h2>\n",
    "          <h3>Comprueba que:</h3>\n",
    "          <p> $\\quad \\bullet$ tu clasificador está almacenado en la variable <b>clf</b><br>\n",
    "              $\\quad \\bullet$ tienes el conjunto de test correctamente almacenado en la variable <b>X_test</b><br>\n",
    "              $\\quad \\bullet$ tienes las etiquetas del conjunto de test correctamente almacenadas en la variable <b>Y_test</b><br>\n",
    "          </p>\n",
    "      \n",
    "  </td>\n",
    " </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ian de la Oliva'] \n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[64  0  0  1]\n",
      " [ 0 45 17  2]\n",
      " [ 2 20 43  0]\n",
      " [ 1  2  2 55]] \n",
      "\n",
      "Outcome:\n",
      "\n",
      "  :) HIT  = 207, (81.50%)\n",
      "  :( FAIL = 47, (18.50%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y_hat = clf.predict(X_test)\n",
    "conf_mat = confusion_matrix(Y_test , Y_hat)\n",
    "N_success  = np.trace(conf_mat)\n",
    "N_fails = Y_test.shape[0]-N_success\n",
    "#-------------------------------\n",
    "print (nombres,\"\\n\")\n",
    "print(\"Confusion matrix:\\n\")\n",
    "print(conf_mat,\"\\n\")\n",
    "print(\"Outcome:\\n\")\n",
    "strlog = \"  :) HIT  = %d, (%0.2f%%)\"%(N_success, 100*N_success/(N_success+N_fails))\n",
    "print(strlog)\n",
    "strlog = \"  :( FAIL = %d, (%0.2f%%)\"%(N_fails, 100*N_fails/(N_success+N_fails))\n",
    "print(strlog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
