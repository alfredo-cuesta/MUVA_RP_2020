{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 2: Problema multiclase\n",
    "\n",
    "Este reto consiste en aprender a clasificar 4 tipos diferentes de vehículos utilizando cualquiera de los clasificadores o técnicas estudiadas hasta el momento. Esto incluye:\n",
    "+ clasificación lineal\n",
    "+ transformaciones no lineales seguido de un clasificador lineal\n",
    "+ Support Vector Machines (SVM)\n",
    "+ Decision Tree (DT)\n",
    "\n",
    "Además se pueden aplicar técnicas de preprocesado como:\n",
    "+ escalado de las características\n",
    "+ *grid search* para búsqueda de hiperparámetros\n",
    "+ validación cruzada\n",
    "\n",
    "El conjunto de datos, *vehiculos_reto2.csv*, consiste en 592 muestras de vehículos; cada uno de ellos representado por 18 características.\n",
    "\n",
    "Para evaluar las propuestas se utilizará un conjunto de datos que se mantendrá oculto hasta después de la entrega\n",
    "\n",
    "### Requisitos\n",
    "+ La entrega se realiza **sólo** a través de la tarea habilitada para ello en la pestaña de *Evaluación* del Aula Virtual.\n",
    "+ Se debe entregar un cuaderno Jupyter con el nombre de los participantes.<br>\n",
    "  *Por ejemplo*:   **Cuesta_LeCunn.ipynb**\n",
    "+ El cuaderno entregado debe seguir la estructura y reglas de este cuaderno\n",
    "\n",
    "### Competición\n",
    "+ Todos los cuadernos entregados se subirán al repo de GitHub y se ejecutarán en Binder, donde ya estará en conjunto de test que permanecía oculto.\n",
    "+ El número de aciertos respecto del número de ejemplos será la puntuación del reto.\n",
    "+ **Importante** Es muy fácil asegurarte de que tu código funcionará bien. Para ello:\n",
    "    1. Agrupa todo tu código en una única celda\n",
    "    2. En el cuaderno del reto que hay en Binder: elimina las celdas que hay entre la verde y la roja, y copia tu celda entre ellas.\n",
    "    3. Ejecuta ese cuaderno de Binder. \n",
    "    \n",
    "### Plazo: lunes 26 de oct. de 2020 a las 6 am.\n",
    "Es decir, incluye toda la noche del domingo 25 de oct.\n",
    "\n",
    "\n",
    "---\n",
    "    [ES] Código de Alfredo Cuesta Infante para 'Reconocimiento de Patrones'\n",
    "       @ Master Universitario en Visión Artificial, 2020, URJC (España)\n",
    "    [EN] Code by Alfredo Cuesta-Infante for 'Pattern Recognition'\n",
    "       @ Master of Computer Vision, 2020, URJC (Spain)\n",
    "\n",
    "    alfredo.cuesta@urjc.es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto distribuido para el reto\n",
    "\n",
    "Challange_filename = '../../Datasets/vehiculos_reto2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto NO distribuido para evaluar los clasificadores entregados\n",
    "\n",
    "Test_filename = '../../Datasets/vehiculos_reto2.csv' #<-- este nombre cambiará después del plazo de entrega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-[1]. Load data from CSV and put all in a single dataframe 'FullSet'\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../../MyUtils/')\n",
    "import MyUtils as my\n",
    "seed = 1234 #<- random generator seed (comment to get randomness)\n",
    "\n",
    "#-[2]. Load data from CSV and put all in a single dataframe 'FullSet'\n",
    "\n",
    "FullSet = pd.read_csv(Challange_filename, header=0)\n",
    "FullX = FullSet.drop('Class', axis=1)\n",
    "FullY = FullSet[['Class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%;\"> \n",
    " <tr style='background:lime'>\n",
    "  <td style=\"text-align:left\">\n",
    "      <h2>Tu código debe empezar a partir de aquí y puede tener tantas celdas como quieras</h2>\n",
    "      <p> Si quieres, puedes borrar (o convertir en RawNBConvert) las celdas de ejemplo\n",
    "      <h3>Importante:</h3>\n",
    "      <p>Tu código debe producir las siguientes variables: </p>\n",
    "      <p> $\\quad \\bullet$ <b>clf:</b> el clasificador final con el que se realizará el test<br>\n",
    "       $\\quad \\bullet$ <b>X_test:</b> el conjunto de test listo para ser usado por el método <b>predict</b><br>\n",
    "       $\\quad \\bullet$ <b>Y_test:</b> es el vector de etiquetas del conjunto de X_test listo para ser usado por el método <b>confusion_matrix</b>\n",
    "      </p>\n",
    "  </td>\n",
    " </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres = [\"Hao Zeng\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- preprocesar para datos --\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(FullX)\n",
    "Y_train=FullY.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluar el modelo con un conjunto de validacion\n",
    "#valid_size=0.2\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#Xtrain,Xvalid,Ytrain,Yvalid=train_test_split(X_train,Y_train,test_size=valid_size,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tasa correcta de kernel linear es 0.747899\n",
      "La tasa correcta de kernel poly es 0.731092\n",
      "La tasa correcta de kernel rbf es 0.680672\n"
     ]
    }
   ],
   "source": [
    "#-Al princippio,decidir usar SVC con diferentes kernels,aqui uso kernel linear,poly y rbf\n",
    "#from sklearn.svm import SVC\n",
    "#Kernel=['linear','poly','rbf']\n",
    "#for kernel in Kernel:\n",
    "    #clf=SVC(kernel=kernel,degree=1,gamma='auto')\n",
    "    #clf.fit(Xtrain,Ytrain)\n",
    "    #print('La tasa correcta de kernel %s es %f'%(kernel,clf.score(Xvalid,Yvalid)))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8605042016806722 {'coef0': 5.26315789473685, 'degree': 2, 'gamma': 0.2976351441631313}\n"
     ]
    }
   ],
   "source": [
    "#Debido a la tasa de linear y de poly es muy similar,pues elegiria GridSearch a poly\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#cv=StratifiedShuffleSplit(n_splits=5,test_size=0.2,random_state=seed)\n",
    "#gamma_range=np.logspace(-10,2,20)\n",
    "#coef0_range=np.linspace(-100,100,20)\n",
    "#degree=[1,2]\n",
    "#param_grid=dict(gamma=gamma_range,coef0=coef0_range,degree=degree)\n",
    "#grid=GridSearchCV(SVC(kernel='poly'),param_grid=param_grid,cv=cv)\n",
    "#grid.fit(X_train,Y_train)\n",
    "#print(grid.best_score_,grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7983193277310925"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cuando coef0=5.2631,degree=2,gamma=0.2976,tendria mejor rendimiento con 86.05%\n",
    "clf=SVC(kernel='poly',gamma=0.2976,coef0=5.2631,degree=2,random_state=seed)\n",
    "clf.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../../Datasets/vehiculos_reto2.csv does not exist: '../../Datasets/vehiculos_reto2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-896978add2f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Debido a la tasa de linear y de poly es muy similar,pues usaria GridSearch a poly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mFullSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTest_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mTestX_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFullSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Class'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mTestY_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFullSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File ../../Datasets/vehiculos_reto2.csv does not exist: '../../Datasets/vehiculos_reto2.csv'"
     ]
    }
   ],
   "source": [
    "FullSet = pd.read_csv(Test_filename, header=0)\n",
    "TestX_ = FullSet.drop('Class', axis=1)\n",
    "TestY_ = FullSet[['Class']]\n",
    "X_test = scaler.transform(TestX_)\n",
    "Y_test = TestY_.values.ravel() \n",
    "#-la evaluación se realiza en las celdas de abajo\n",
    "\n",
    "'''RESULTADO: X_test es el dataframe para utilizar en >>> Y_pred = clf.predict() \n",
    "   RESULTADO: Y_test es el array con las etiquetas para utilizar en >>> confusion_matrix(Y_test,Y_pred)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%;\"> \n",
    " <tr style='background:pink'>\n",
    "  <td style=\"text-align:left\">\n",
    "      <h2>A partir de aquí ya no se pueden modificar las celdas</h2>\n",
    "          <h3>Comprueba que:</h3>\n",
    "          <p> $\\quad \\bullet$ tu clasificador está almacenado en la variable <b>clf</b><br>\n",
    "              $\\quad \\bullet$ tienes el conjunto de test correctamente almacenado en la variable <b>X_test</b><br>\n",
    "              $\\quad \\bullet$ tienes las etiquetas del conjunto de test correctamente almacenadas en la variable <b>Y_test</b><br>\n",
    "          </p>\n",
    "      \n",
    "  </td>\n",
    " </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alfredo Cuesta', 'Yann LeCun'] \n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[153   0   0   0]\n",
      " [  0 148   0   0]\n",
      " [  0   0 152   0]\n",
      " [  0   0   0 139]] \n",
      "\n",
      "Outcome:\n",
      "\n",
      "  :) HIT  = 592, (100.00%)\n",
      "  :( FAIL = 0, (0.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y_hat = clf.predict(X_test)\n",
    "conf_mat = confusion_matrix(Y_test , Y_hat)\n",
    "N_success  = np.trace(conf_mat)\n",
    "N_fails = Y_test.shape[0]-N_success\n",
    "#-------------------------------\n",
    "print (nombres,\"\\n\")\n",
    "print(\"Confusion matrix:\\n\")\n",
    "print(conf_mat,\"\\n\")\n",
    "print(\"Outcome:\\n\")\n",
    "strlog = \"  :) HIT  = %d, (%0.2f%%)\"%(N_success, 100*N_success/(N_success+N_fails))\n",
    "print(strlog)\n",
    "strlog = \"  :( FAIL = %d, (%0.2f%%)\"%(N_fails, 100*N_fails/(N_success+N_fails))\n",
    "print(strlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
